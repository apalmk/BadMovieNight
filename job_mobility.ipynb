{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job_mobility.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcnrUb14htASI5XtQ0qYS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apalmk/BadMovieNight/blob/master/job_mobility.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnLJ37xvPhqi",
        "colab_type": "text"
      },
      "source": [
        "##Importing the data into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buHxJ98lPkku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from urllib.request import urlopen\n",
        "from nltk.stem.snowball import EnglishStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import word_tokenize     \n",
        "import nltk     \n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7b1T6QMPewM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"corpclimate_assessment.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE6mqqqEP6De",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "48ed2177-3565-4ffb-a24f-760bd8872c9f"
      },
      "source": [
        "df['Description']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  All Accounting Duties\n",
              "1      We offer great service backed with 35+ years o...\n",
              "2      Specialized in installing garage doors and gar...\n",
              "3                                running the whole show!\n",
              "4      Running the day to day operations of the bussi...\n",
              "                             ...                        \n",
              "295    <U+F0B2>\\tInstrumental in growing iGATE busine...\n",
              "296    My first working place. Unforgettable moments....\n",
              "297    responsible to support the Regional Audit Asia...\n",
              "298    Spokesperson,Served as a mentor to Junior and ...\n",
              "299    conseptual design, detail design, prepared tec...\n",
              "Name: Description, Length: 300, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2JqIE3HAipi",
        "colab_type": "text"
      },
      "source": [
        "##Extracting names from the ID column\n",
        "\n",
        "To extract the names from the ID column I split on the hyphen and took the first two words (first name, and the last name) that had length>1 and only consisted of alphabets after the split. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iqx1ZnrQFdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "li=list(df['ID'])\n",
        "names=[]\n",
        "c=0\n",
        "for i in li:\n",
        "  w=re.split(r'-',i)\n",
        "  n=\"\"\n",
        "  c=0\n",
        "  for j in w:\n",
        "    if len(j)>1:\n",
        "      #Getting the first and the last name from the ID column\n",
        "      if c<=1:\n",
        "        if j.isalpha() and (j!=\"md\" or j!=\"phd\"):\n",
        "          n=n+j+\" \"\n",
        "          c=c+1\n",
        "  names.append(n.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB3aQoyFBgps",
        "colab_type": "text"
      },
      "source": [
        "We have observed that some IDs had company names instead of the names of the people in them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI7v5PFliBzo",
        "colab_type": "text"
      },
      "source": [
        "##Getting the gender of the person from the name\n",
        "\n",
        "I used the gender API to identify the gender of the person from his/her name. The gender API returns unknown if the gender can't be known from the name. In our case the names of businesses such as \"drain services\" etc don't have a gender. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DSiE0Ntil41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gender(name):\n",
        "  myKey = \"ojShYjxwnEaMgXWjgk\"\n",
        "  url = \"https://gender-api.com/get?key=\" + myKey + \"&name=\"+name\n",
        "  response = urlopen(url)\n",
        "  decoded = response.read().decode('utf-8')\n",
        "  data = json.loads(decoded)\n",
        "  return data[\"gender\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGldhnzNTvnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting the gender from the name\n",
        "gender=[]\n",
        "for i in names:\n",
        "  if i == \"\":\n",
        "    gender.append(\"unknown\")\n",
        "  else:\n",
        "    gender.append(get_gender(i.split(\" \")[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cGj040dnFNJ",
        "colab_type": "text"
      },
      "source": [
        "##Identifying the type of job from the descriptions\n",
        "\n",
        "For this taks we can either use LDA or NMF. We will be using LDA and identifying the prevelant topics in the texts of the description, and then seeing what topic is mostly present in each document (i.e. for each person)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFSDiWbfoYJ5",
        "colab_type": "text"
      },
      "source": [
        "1. Making a bag of words model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xi538Rhqyx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = list(df['Description'])\n",
        "\n",
        "#Adding task speicific stop words\n",
        "my_stopwords = set(ENGLISH_STOP_WORDS)\n",
        "my_stopwords.add(\"and\")\n",
        "my_stopwords.add(\"of\")\n",
        "my_stopwords.add(\"to\")\n",
        "my_stopwords.add(\"for\")\n",
        "my_stopwords.add(\"the\")\n",
        "my_stopwords.add(\"in\")\n",
        "my_stopwords.add(\"as\")\n",
        "my_stopwords.add(\"de\")\n",
        "my_stopwords.add(\"et\")\n",
        "my_stopwords.add(\"all\")\n",
        "my_stopwords.add(\"en\")\n",
        "my_stopwords.add(\"la\")\n",
        "my_stopwords.add(\"het\")\n",
        "my_stopwords.add(\"es\")\n",
        "my_stopwords.add(\"do\")\n",
        "my_stopwords.add(\"pt\")\n",
        "my_stopwords.add(\"with\")\n",
        "my_stopwords.add(\"des\")\n",
        "my_stopwords.add(\"une\")\n",
        "my_stopwords.add(\"las\")\n",
        "my_stopwords.add(\"van\")\n",
        "my_stopwords.add(\"del\")\n",
        "\n",
        "\n",
        "#Making the bag of words model\n",
        "vect = CountVectorizer(ngram_range=(1, 3),stop_words=my_stopwords, lowercase=True)\n",
        "bow = vect.fit_transform(data).todense()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuH0orMAq8CJ",
        "colab_type": "text"
      },
      "source": [
        "2. Using LDA to identify the topics and percentage of these topics in each document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97npyCMZsteu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = LatentDirichletAllocation(n_components=25, learning_method=\"batch\")\n",
        "d_lda = lda.fit_transform(bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvWsQbJaxDcS",
        "colab_type": "text"
      },
      "source": [
        "We have chosen to represent each job into 25 topics, we will now look at what top 5 words that contribute to each topic to identify what job each topic might be modeling. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtJez5jjypTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_key(n):\n",
        "  for word, num in vect.vocabulary_.items():\n",
        "    if num ==n:\n",
        "        return word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S5QLF4bwGtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "57148aff-f4cf-4156-827e-48f3ada25046"
      },
      "source": [
        "topic_words = {}\n",
        "\n",
        "for topic, comp in enumerate(lda.components_): \n",
        "    word_idx = np.argsort(comp)[::-1][:5]\n",
        "    topic_words[topic] = [get_key(i) for i in word_idx]\n",
        "\n",
        "for topic, words in topic_words.items():\n",
        "    print('Topic: %d' % topic)\n",
        "    print('  %s' % ', '.join(words))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0\n",
            "  application, needs, department, control, insurance\n",
            "Topic: 1\n",
            "  engineering, design, unit, chemical, sp\n",
            "Topic: 2\n",
            "  2013, general, store, april, december\n",
            "Topic: 3\n",
            "  exchange, company, project, mas, fui aprendendo\n",
            "Topic: 4\n",
            "  teacher, com, study, job, aan\n",
            "Topic: 5\n",
            "  clients, planning, media, f0a7, management\n",
            "Topic: 6\n",
            "  records, f0b2, japan, management, business\n",
            "Topic: 7\n",
            "  projects, project, power, support, plant\n",
            "Topic: 8\n",
            "  certificate, training, al, leighton, services\n",
            "Topic: 9\n",
            "  activities, general, design, training, technical\n",
            "Topic: 10\n",
            "  militares, da, ex, rcito, ex rcito\n",
            "Topic: 11\n",
            "  sales, business, project, management, market\n",
            "Topic: 12\n",
            "  assisted, design, rãƒâ, services, trading\n",
            "Topic: 13\n",
            "  water, treatment, service, water treatment, cooling\n",
            "Topic: 14\n",
            "  staff, department, housekeeping, ensure, books\n",
            "Topic: 15\n",
            "  control, voor, proceso, design, group\n",
            "Topic: 16\n",
            "  financial, audit, customer, voor, research\n",
            "Topic: 17\n",
            "  maintenance, inspection, site, products, staff\n",
            "Topic: 18\n",
            "  department, derecho, vsl, personal, gestion\n",
            "Topic: 19\n",
            "  sales, computo, specialist, handling, le\n",
            "Topic: 20\n",
            "  f076, support, analysis, department, market\n",
            "Topic: 21\n",
            "  pressure, f0fc, company, technology, trading\n",
            "Topic: 22\n",
            "  management, 0442, 043c, 0430, 0438\n",
            "Topic: 23\n",
            "  quality, services, community, water, 0627\n",
            "Topic: 24\n",
            "  responsible, configuration, installation, project, involved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BoIjRkr2yu3",
        "colab_type": "text"
      },
      "source": [
        "From the above output we can see that the topic0 covers insurance and application oriented jobs, the topic1 covers engineering, chemical engineering and design. Now the d_lda matrix tells us how much each person belong to each topic we identified. Let us have a look at one row in the matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCE3vBtW3qNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "38f44acb-5b95-49d9-bd76-11f435868e70"
      },
      "source": [
        "d_lda[0]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.76, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVAXGRYs3zpV",
        "colab_type": "text"
      },
      "source": [
        "We can see that the person 1 does jobs relating to topic 19 (computer sales and specialist) with high probability (76%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaZ12oYw4YFP",
        "colab_type": "text"
      },
      "source": [
        "3. We will now merge the gender list with matrix obtained above and build a logistic regression classifier. We will try to predict the gender from the participation of the person in the topics (from his possible job). The coefficients of each of the 25 topics will tell us which topic (set of jobs) contribute highly to classification of genders. This gives the jobs that pre-dominantly employ one gender more than the other. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8jDHdAr46yV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#making numpy array from matrix\n",
        "a = np.asarray(d_lda)\n",
        "\n",
        "a1 = np.hstack((a,np.asarray(gender).reshape(-1,1)))\n",
        "\n",
        "#Making a list for the column names\n",
        "ln=[]\n",
        "for i in range(0,26):\n",
        "  ln.append(\"column\"+str(i))\n",
        "\n",
        "\n",
        "#Making the array into a dataframe\n",
        "ddf= pd.DataFrame(a1, columns=ln)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm0Pqk5C6zng",
        "colab_type": "text"
      },
      "source": [
        "We will be removing rows that have gender as unknown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcsJyCHM62_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ddf1= ddf[ddf[\"column25\"]!='unknown']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cKpGSv5vNFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1abf5d9c-0a76-4600-c7c1-a4971c4820ce"
      },
      "source": [
        "ddf1.shape"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(263, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgEGECNp8MFx",
        "colab_type": "text"
      },
      "source": [
        "We lost 37 rows that had gender as unknown"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1guE1SuU8KSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0d9b3e0e-7d52-438e-a3e0-dbbaf78039fd"
      },
      "source": [
        "X=ddf1.loc[:, ddf1.columns != 'column25']\n",
        "y = ddf1[\"column25\"]\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X, y)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmSlnAv6-QPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "98333530-b435-4ddf-e3e2-0207803d66a8"
      },
      "source": [
        "lr.coef_"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.37935867, -0.25280998, -0.79040919, -0.74956658,  0.61498461,\n",
              "         0.44146906,  0.09473661,  0.54731516,  0.7276716 ,  0.11747732,\n",
              "         0.52918818,  0.40968386, -0.7067211 ,  0.19102825,  0.31344065,\n",
              "        -0.46633067, -0.49928982,  0.02201175,  0.62301074, -0.39486904,\n",
              "         0.15810998, -1.22262023,  0.09408712, -0.24970439,  0.06878837]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQxudXsd9Leb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3fef8b22-95d5-477c-b121-a68cd35d2887"
      },
      "source": [
        "#Multiplied -1 to get the descending order\n",
        "np.argsort(list(-1*lr.coef_))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8, 18,  4,  7, 10,  5, 11,  0, 14, 13, 20,  9,  6, 22, 24, 17,\n",
              "        23,  1, 19, 15, 16, 12,  3,  2, 21]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0K09F2J9qdc",
        "colab_type": "text"
      },
      "source": [
        "We can see that the jobs denoted by topic 8 (certification and training services) have predominantly employed one of the genders, then comes jobs by topic 18 (gestion (Spanish for Management, personal assistance departments)) and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBgCuLokj08-",
        "colab_type": "text"
      },
      "source": [
        "##Making a new dataframe and generating an excel sheet from this new dataframe\n",
        "\n",
        "Let us make a new data frame from the cleaned data we obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcnoHW03C67Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ddf1.to_csv(\"final.csv\", sep='\\t', encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zxi6VgXAamk",
        "colab_type": "text"
      },
      "source": [
        "##Comments and observartions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzZobVmE_mls",
        "colab_type": "text"
      },
      "source": [
        "Comments and Observations:\n",
        "\n",
        "1. The data was noisy and had multiple languages (English, French, Spanish etc.).\n",
        "\n",
        "2. The ID column sometimes had names of the people and sometimes had names of the companies. Ex: 'a-1-business-solutions-pllc-b318b6a9'\n",
        "\n",
        "\n",
        "3. If we increase the no of topics we are obtaining (here we only did for 25 topics), we can have more accurate job representations.\n",
        "\n",
        "4. Some ID values did not have any names in them.  Ex:  ‘a-a-c-a5863310’"
      ]
    }
  ]
}